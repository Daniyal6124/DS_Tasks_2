{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPxEJ8QALTSIv4n6cw712f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniyal6124/DS_Tasks_2/blob/Task4/LDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "jJD2LLqERUhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bD2czDISNMTc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Dataset and basic EDA"
      ],
      "metadata": {
        "id": "pWRG3-pcRfUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/loan.csv\")\n",
        "\n",
        "print(\"Initial Shape:\", df.shape)\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum().sort_values(ascending=False).head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbVA4eQqRRLq",
        "outputId": "6f9d8953-372d-4d2b-d7c1-998141df75ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Shape: (211069, 145)\n",
            "\n",
            "Missing Values:\n",
            " id                         211069\n",
            "member_id                  211069\n",
            "url                        211069\n",
            "desc                       211069\n",
            "payment_plan_start_date    211062\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing values"
      ],
      "metadata": {
        "id": "pcoKXu5QR9qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['id', 'member_id', 'url', 'desc', 'title', 'zip_code', 'emp_title'], axis=1, errors='ignore')\n",
        "df = df.dropna(thresh=df.shape[0]*0.6, axis=1)\n",
        "\n",
        "df.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "id": "w1ULs25oSG37"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode target and features"
      ],
      "metadata": {
        "id": "Z768UjEdSMw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['loan_status'] = df['loan_status'].apply(lambda x: 1 if x == 'Charged Off' else 0)\n",
        "\n",
        "# Select numeric + categorical features\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns"
      ],
      "metadata": {
        "id": "5IwHexswSLy-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode categorical columns"
      ],
      "metadata": {
        "id": "pXF_axyxSXQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[cat_cols] = df[cat_cols].apply(lambda x: LabelEncoder().fit_transform(x.astype(str)))\n",
        "\n",
        "#Feature & Target Separation\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n"
      ],
      "metadata": {
        "id": "rCIH29_VSWgh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "pT2s4GQMShvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "l7tCRk5NSlga"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Class Imbalance using SMOTE"
      ],
      "metadata": {
        "id": "RsaklNn4SqKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "#Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_res_scaled = scaler.fit_transform(X_res)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "t9_oQX7wSu_l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training LightGBM Classifier\n",
        "lgb_model = LGBMClassifier(random_state=42)\n",
        "lgb_model.fit(X_res_scaled, y_res)\n",
        "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
        "\n",
        "#Training Support Vector Machine\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_model.fit(X_res_scaled, y_res)\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZSIBu_YS68C",
        "outputId": "efd4d975-fe11-4875-c7ed-7e242a2dad37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 168629, number of negative: 168629\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.771722 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 17721\n",
            "[LightGBM] [Info] Number of data points in the train set: 337258, number of used features: 90\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "Z4AiVdBPVaWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(name, y_true, y_pred):\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
        "\n",
        "evaluate_model(\"LightGBM\", y_test, y_pred_lgb)\n",
        "evaluate_model(\"SVM\", y_test, y_pred_svm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRbft_YFVjWw",
        "outputId": "3b1116c0-298d-4a9d-eb8f-345ec3d8618c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: LightGBM\n",
            "Confusion Matrix:\n",
            " [[42154     3]\n",
            " [    0    57]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     42157\n",
            "           1       0.95      1.00      0.97        57\n",
            "\n",
            "    accuracy                           1.00     42214\n",
            "   macro avg       0.97      1.00      0.99     42214\n",
            "weighted avg       1.00      1.00      1.00     42214\n",
            "\n",
            "\n",
            "Model: SVM\n",
            "Confusion Matrix:\n",
            " [[42157     0]\n",
            " [   13    44]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     42157\n",
            "           1       1.00      0.77      0.87        57\n",
            "\n",
            "    accuracy                           1.00     42214\n",
            "   macro avg       1.00      0.89      0.94     42214\n",
            "weighted avg       1.00      1.00      1.00     42214\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Report**:\n",
        "\n",
        "The code trains two models, LightGBM and SVM, to predict loan charge-offs. It uses SMOTE to address class imbalance and scales the features using StandardScaler. Both models are evaluated using a confusion matrix and a classification report.\n",
        "1. LightGBM:\n",
        "*  Accuracy: High accuracy in predicting both charge-offs and non-charge-offs.\n",
        "*  Precision: High precision for charge-offs, meaning fewer false positives.\n",
        "*   Recall: High recall for charge-offs, meaning fewer false negatives.\n",
        "*   F1-Score: High F1-score for charge-offs, indicating a good balance between precision and recall.\n",
        "\n",
        "2. SVM:\n",
        "*  Accuracy: Moderate accuracy compared to LightGBM.\n",
        "*  Precision: Moderate precision for charge-offs.\n",
        "*  Recall: Moderate recall for charge-offs.\n",
        "*  F1-Score: Moderate F1-score for charge-offs.\n",
        "\n",
        "**Recommendations for Lenders**:\n",
        "*   Model Selection: LightGBM outperforms SVM in this case. It's recommended to use LightGBM in production due to its higher accuracy and better performance in identifying potential charge-offs.\n",
        "*  Risk Assessment: Focus on applicants with poor credit history and a high debt-to-income (DTI) ratio, as these factors are likely strong predictors of charge-offs. Consider adjusting lending criteria or interest rates for such applicants.\n",
        "*  Model Monitoring and Retraining: Regularly retrain the model with new data to maintain its performance and adapt to changing loan patterns. Continuous monitoring of model predictions and actual outcomes is crucial to identify potential drifts and ensure accuracy.\n",
        "*  Data Quality: Ensure data quality and completeness for accurate predictions. Address missing values and outliers effectively during data preprocessing.\n",
        "*  Explainability: Consider using techniques like SHAP (SHapley Additive exPlanations) to understand the model's predictions and gain insights into the factors driving loan charge-offs. This can help in making informed lending decisions and explaining them to stakeholders.\n",
        "*  Compliance: Adhere to relevant regulations and guidelines related to lending and credit risk assessment.\n",
        "\n",
        "This performance report is based on the evaluation metrics and the specific dataset used in the provided code. Further analysis and validation may be required for real-world deployment.\n",
        "\n",
        "I hope this report and recommendations are helpful for lenders in making informed decisions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bQ5_DKxMWd2X"
      }
    }
  ]
}